{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roslyn_TD_Label_Predict_Single.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xIbLyam6PAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c036ed5c-e978-4fb0-d2c5-fbe9a40b550b"
      },
      "source": [
        "#This Code predict Label for SVF Issues with Title\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import preprocessing\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "data = pd.read_csv('IssueDetailsRoslyn_02112019.csv')\n",
        "# frac=1 means return all rows (in random order)\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "y = list(data['Label']) \n",
        "x = list(data['Title_Description']) \n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "\n",
        "categories = list(set(y))\n",
        "\n",
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "test = encode(le,categories)\n",
        "\n",
        "untest = decode(le, test)\n",
        "\n",
        "\n",
        "x_enc = x\n",
        "y_enc = encode(le, y)\n",
        "\n",
        "#80% / 20% train / test split:\n",
        "\n",
        "train_size = int(len(x) * .8)\n",
        "\n",
        "x_train = np.asarray(x_enc[:train_size])\n",
        "y_train = np.asarray(y_enc[:train_size])\n",
        "\n",
        "x_test = np.asarray(x_enc[train_size:])\n",
        "y_test = np.asarray(y_enc[train_size:])\n",
        "\n",
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)))\n",
        "\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(len(categories), activation='softmax')(dense)\n",
        "adam = Adam(lr=0.04)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=40)\n",
        "    model.save_weights('./Roslyn_TD_Label_Predict_Single.h5')\n",
        "    predicts = model.predict(x_test, batch_size=40)  \n",
        "\n",
        "y_test = np.asarray(y_enc[train_size:])\n",
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_preds)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8762/8762 [==============================] - 611s 70ms/step - loss: 1.9313 - acc: 0.4388\n",
            "Epoch 2/10\n",
            "8762/8762 [==============================] - 603s 69ms/step - loss: 1.6235 - acc: 0.4912\n",
            "Epoch 3/10\n",
            "8762/8762 [==============================] - 600s 68ms/step - loss: 1.5699 - acc: 0.5007\n",
            "Epoch 4/10\n",
            "8762/8762 [==============================] - 604s 69ms/step - loss: 1.5698 - acc: 0.5090\n",
            "Epoch 5/10\n",
            "8762/8762 [==============================] - 599s 68ms/step - loss: 1.5223 - acc: 0.5175\n",
            "Epoch 6/10\n",
            "8762/8762 [==============================] - 599s 68ms/step - loss: 1.4985 - acc: 0.5226\n",
            "Epoch 7/10\n",
            "8762/8762 [==============================] - 606s 69ms/step - loss: 1.4843 - acc: 0.5334\n",
            "Epoch 8/10\n",
            "8762/8762 [==============================] - 599s 68ms/step - loss: 1.4702 - acc: 0.5305\n",
            "Epoch 9/10\n",
            "8762/8762 [==============================] - 598s 68ms/step - loss: 1.4624 - acc: 0.5347\n",
            "Epoch 10/10\n",
            "8762/8762 [==============================] - 599s 68ms/step - loss: 1.4602 - acc: 0.5381\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                   0 - Backlog       0.57      0.14      0.22        29\n",
            "                  1 - Planning       0.00      0.00      0.00         2\n",
            "               13/01/2016 6:57       0.00      0.00      0.00         1\n",
            "                     2 - Ready       0.00      0.00      0.00         1\n",
            "               20/02/2016 5:41       0.00      0.00      0.00         1\n",
            "                   3 - Working       0.00      0.00      0.00         3\n",
            "               31/05/2017 2:31       0.00      0.00      0.00         0\n",
            "                 4 - In Review       0.00      0.00      0.00        36\n",
            "                6/04/2017 4:15       0.00      0.00      0.00         1\n",
            "             Approved to merge       0.41      0.45      0.43       179\n",
            "                Area-Analyzers       0.37      0.25      0.30       116\n",
            "                Area-Compilers       0.50      0.59      0.54       560\n",
            "                 Area-External       0.00      0.00      0.00        28\n",
            "                      Area-IDE       0.49      0.65      0.56       522\n",
            "           Area-Infrastructure       0.58      0.73      0.65       271\n",
            "              Area-Interactive       0.00      0.00      0.00        56\n",
            "          Area-Language Design       0.40      0.64      0.49        33\n",
            "              Area-Performance       0.00      0.00      0.00        14\n",
            "          Area-SDK and Samples       0.00      0.00      0.00         3\n",
            "      Auto-Merge If Tests Pass       0.00      0.00      0.00         6\n",
            "                           Bug       0.00      0.00      0.00         6\n",
            "                     Community       0.00      0.00      0.00         6\n",
            "Concept-Continuous Improvement       0.00      0.00      0.00         1\n",
            "                 Disabled Test       0.00      0.00      0.00         1\n",
            "                 Documentation       0.00      0.00      0.00         1\n",
            "               Feature Request       0.00      0.00      0.00         2\n",
            "         Interactive-Debugging       0.00      0.00      0.00         1\n",
            "               Interactive-EnC       0.00      0.00      0.00         2\n",
            "   New Feature - Flow Analysis       0.00      0.00      0.00         2\n",
            "      New Feature - IOperation       0.00      0.00      0.00         1\n",
            " New Language Feature - Tuples       0.00      0.00      0.00         1\n",
            "   PR For Personal Review Only       0.22      0.38      0.28        13\n",
            "                      Question       0.00      0.00      0.00         3\n",
            "          Resolution-By Design       0.00      0.00      0.00         2\n",
            "          Resolution-Duplicate       0.00      0.00      0.00         9\n",
            "            cla-already-signed       0.52      0.22      0.31       220\n",
            "                           nan       1.00      0.72      0.84        58\n",
            "\n",
            "                      accuracy                           0.50      2191\n",
            "                     macro avg       0.14      0.13      0.12      2191\n",
            "                  weighted avg       0.46      0.50      0.47      2191\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pckCKEEe6q4g",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}