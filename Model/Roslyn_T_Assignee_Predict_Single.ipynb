{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVF_Title_Assignee_Predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xIbLyam6PAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This Code predict Label for SVF Issues with Title\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "data = pd.read_csv('IssueDetailsRoslyn_20102019_Single.csv')\n",
        "data = data.sample(frac=1)\n",
        "\n",
        "\n",
        "y = list(data['Assignee']) \n",
        "x = list(data['Title']) \n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "\n",
        "categories = list(set(y))\n",
        "\n",
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "test = encode(le,categories)\n",
        "\n",
        "untest = decode(le, test)\n",
        "\n",
        "\n",
        "x_enc = x\n",
        "y_enc = encode(le, y)\n",
        "\n",
        "#80% / 20% train / test split:\n",
        "\n",
        "train_size = int(len(x) * .8)\n",
        "\n",
        "x_train = np.asarray(x_enc[:train_size])\n",
        "y_train = np.asarray(y_enc[:train_size])\n",
        "\n",
        "x_test = np.asarray(x_enc[train_size:])\n",
        "y_test = np.asarray(y_enc[train_size:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxgn6vzHdReY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfe-mPpJdUA0",
        "colab_type": "code",
        "outputId": "1af73d4b-7400-44f6-ebde-84785d34dacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(len(categories), activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5QKGbCdWEs",
        "colab_type": "code",
        "outputId": "3aa58dfc-5bc0-4b28-e500-e0af86feaaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=60, batch_size=32)\n",
        "    model.save_weights('./Roslyn_TD_Assignee_Predict_Single.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "715/715 [==============================] - 14s 20ms/step - loss: 3.5244 - acc: 0.2727\n",
            "Epoch 2/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.7512 - acc: 0.3119\n",
            "Epoch 3/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.5367 - acc: 0.3021\n",
            "Epoch 4/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.4342 - acc: 0.3441\n",
            "Epoch 5/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.3600 - acc: 0.3413\n",
            "Epoch 6/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.2900 - acc: 0.3846\n",
            "Epoch 7/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.2348 - acc: 0.3804\n",
            "Epoch 8/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.1734 - acc: 0.3930\n",
            "Epoch 9/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.1280 - acc: 0.4140\n",
            "Epoch 10/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.0705 - acc: 0.4280\n",
            "Epoch 11/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 2.0237 - acc: 0.4420\n",
            "Epoch 12/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.9677 - acc: 0.4490\n",
            "Epoch 13/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.9280 - acc: 0.4713\n",
            "Epoch 14/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.8823 - acc: 0.4811\n",
            "Epoch 15/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.8403 - acc: 0.4853\n",
            "Epoch 16/60\n",
            "715/715 [==============================] - 8s 11ms/step - loss: 1.7852 - acc: 0.5021\n",
            "Epoch 17/60\n",
            "715/715 [==============================] - 8s 11ms/step - loss: 1.7428 - acc: 0.5161\n",
            "Epoch 18/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.6926 - acc: 0.5315\n",
            "Epoch 19/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.6534 - acc: 0.5343\n",
            "Epoch 20/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.6128 - acc: 0.5538\n",
            "Epoch 21/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.5770 - acc: 0.5510\n",
            "Epoch 22/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.5345 - acc: 0.5636\n",
            "Epoch 23/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.4909 - acc: 0.5790\n",
            "Epoch 24/60\n",
            "715/715 [==============================] - 8s 11ms/step - loss: 1.4584 - acc: 0.5846\n",
            "Epoch 25/60\n",
            "715/715 [==============================] - 8s 12ms/step - loss: 1.4273 - acc: 0.5986\n",
            "Epoch 26/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.3919 - acc: 0.5986\n",
            "Epoch 27/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.3488 - acc: 0.6182\n",
            "Epoch 28/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.3173 - acc: 0.6252\n",
            "Epoch 29/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.2817 - acc: 0.6573\n",
            "Epoch 30/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.2480 - acc: 0.6517\n",
            "Epoch 31/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.2191 - acc: 0.6629\n",
            "Epoch 32/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.1947 - acc: 0.6783\n",
            "Epoch 33/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.1526 - acc: 0.6909\n",
            "Epoch 34/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.1289 - acc: 0.6909\n",
            "Epoch 35/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.1008 - acc: 0.6979\n",
            "Epoch 36/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.0731 - acc: 0.7091\n",
            "Epoch 37/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.0395 - acc: 0.7343\n",
            "Epoch 38/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 1.0093 - acc: 0.7273\n",
            "Epoch 39/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.9872 - acc: 0.7469\n",
            "Epoch 40/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.9659 - acc: 0.7552\n",
            "Epoch 41/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.9373 - acc: 0.7538\n",
            "Epoch 42/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.9197 - acc: 0.7650\n",
            "Epoch 43/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.8941 - acc: 0.7720\n",
            "Epoch 44/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.8708 - acc: 0.7888\n",
            "Epoch 45/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.8497 - acc: 0.8028\n",
            "Epoch 46/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.8295 - acc: 0.8084\n",
            "Epoch 47/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.8054 - acc: 0.8112\n",
            "Epoch 48/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.7887 - acc: 0.8182\n",
            "Epoch 49/60\n",
            "715/715 [==============================] - 10s 14ms/step - loss: 0.7744 - acc: 0.8308\n",
            "Epoch 50/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.7528 - acc: 0.8252\n",
            "Epoch 51/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.7331 - acc: 0.8448\n",
            "Epoch 52/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.7128 - acc: 0.8462\n",
            "Epoch 53/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.7033 - acc: 0.8462\n",
            "Epoch 54/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6825 - acc: 0.8503\n",
            "Epoch 55/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6616 - acc: 0.8643\n",
            "Epoch 56/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6532 - acc: 0.8545\n",
            "Epoch 57/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6388 - acc: 0.8741\n",
            "Epoch 58/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6190 - acc: 0.8713\n",
            "Epoch 59/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.6020 - acc: 0.8741\n",
            "Epoch 60/60\n",
            "715/715 [==============================] - 9s 12ms/step - loss: 0.5886 - acc: 0.8727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh7KFTBXdaj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./Roslyn_TD_Assignee_Predict_Single.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=32)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbFylyoyks9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVG_eZ8jdbzN",
        "colab_type": "code",
        "outputId": "10a62f90-6fd8-40b4-a20f-a44f6a3cb51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "y_test = np.asarray(y_enc[train_size:])\n",
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_preds)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        333fred       0.00      0.00      0.00         2\n",
            "      AlekseyTs       0.00      0.00      0.00         4\n",
            " CyrusNajmabadi       0.00      0.00      0.00         2\n",
            "      JoeRobich       0.25      0.40      0.31         5\n",
            "    RikkiGibson       0.00      0.00      0.00         6\n",
            "          abock       0.00      0.00      0.00         1\n",
            "         agocke       0.00      0.00      0.00         7\n",
            "    allisonchou       0.50      0.50      0.50         2\n",
            "         chborl       0.00      0.00      0.00         3\n",
            "       chsienki       0.00      0.00      0.00         1\n",
            "       dibarbet       0.00      0.00      0.00         6\n",
            "     dotnet-bot       0.94      1.00      0.97        29\n",
            "         gafter       0.30      0.45      0.36        20\n",
            "          genlu       0.00      0.00      0.00         5\n",
            "     huoyaoyuan       0.00      0.00      0.00         1\n",
            "      ivanbasov       0.00      0.00      0.00         7\n",
            "       jaredpar       0.00      0.00      0.00         8\n",
            "jasonmalinowski       0.00      0.00      0.00         5\n",
            "          jcouv       0.29      0.31      0.30        13\n",
            "     jinujoseph       0.00      0.00      0.00         3\n",
            "        jmarolf       0.00      0.00      0.00         1\n",
            "           jnm2       0.00      0.00      0.00         1\n",
            "       mavasani       0.15      0.22      0.18         9\n",
            "      nnpcYvIVl       0.25      0.50      0.33         2\n",
            "       petrroll       0.00      0.00      0.00         0\n",
            "   reaction1989       0.00      0.00      0.00         1\n",
            "       ryzngard       0.00      0.00      0.00         6\n",
            "       sharwell       0.41      0.60      0.49        20\n",
            "    stephentoub       0.00      0.00      0.00         1\n",
            "           tmat       0.00      0.00      0.00         7\n",
            "      tmeschter       0.00      0.00      0.00         0\n",
            "vatsalyaagrawal       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.34       179\n",
            "      macro avg       0.10      0.12      0.11       179\n",
            "   weighted avg       0.28      0.34      0.30       179\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNG02At0yGXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pckCKEEe6q4g",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}