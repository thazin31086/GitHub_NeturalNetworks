{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xIbLyam6PAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This Code predict Label for SVF Issues \n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "data = pd.read_csv('IssueDetailsSVF_20102019.csv')\n",
        "\n",
        "y = list(data['Label']) \n",
        "x = list(data['Title_Description']) \n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "\n",
        "categories = list(set(y))\n",
        "\n",
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "test = encode(le,categories)\n",
        "\n",
        "untest = decode(le, test)\n",
        "\n",
        "\n",
        "x_enc = x\n",
        "y_enc = encode(le, y)\n",
        "\n",
        "x_train = np.asarray(x_enc[:80])\n",
        "y_train = np.asarray(y_enc[:80])\n",
        "\n",
        "\n",
        "x_test = np.asarray(x_enc[80:])\n",
        "y_test = np.asarray(y_enc[80:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxgn6vzHdReY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfe-mPpJdUA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62e3cabd-364e-41d7-8bef-c43ac77f585e"
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(len(categories), activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5QKGbCdWEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3cd9fe4-2ec3-4b90-c5aa-811ac4088f17"
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=30, batch_size=32)\n",
        "    model.save_weights('./model.h5')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "80/80 [==============================] - 8s 101ms/step - loss: 2.6610 - acc: 0.3250\n",
            "Epoch 2/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 2.4567 - acc: 0.5125\n",
            "Epoch 3/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 2.2763 - acc: 0.5125\n",
            "Epoch 4/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 2.0973 - acc: 0.5125\n",
            "Epoch 5/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.9274 - acc: 0.5125\n",
            "Epoch 6/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.8151 - acc: 0.5125\n",
            "Epoch 7/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.7434 - acc: 0.5125\n",
            "Epoch 8/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.7084 - acc: 0.5125\n",
            "Epoch 9/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.6833 - acc: 0.5125\n",
            "Epoch 10/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.6505 - acc: 0.5125\n",
            "Epoch 11/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.6188 - acc: 0.5125\n",
            "Epoch 12/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.5815 - acc: 0.5375\n",
            "Epoch 13/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.5620 - acc: 0.5375\n",
            "Epoch 14/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.5331 - acc: 0.5500\n",
            "Epoch 15/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.5068 - acc: 0.5500\n",
            "Epoch 16/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.4825 - acc: 0.5500\n",
            "Epoch 17/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.4584 - acc: 0.5500\n",
            "Epoch 18/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.4287 - acc: 0.5500\n",
            "Epoch 19/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.4055 - acc: 0.5500\n",
            "Epoch 20/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.3804 - acc: 0.5500\n",
            "Epoch 21/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.3532 - acc: 0.5500\n",
            "Epoch 22/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.3279 - acc: 0.5625\n",
            "Epoch 23/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.3040 - acc: 0.6000\n",
            "Epoch 24/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.2832 - acc: 0.6125\n",
            "Epoch 25/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.2575 - acc: 0.6125\n",
            "Epoch 26/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.2312 - acc: 0.6125\n",
            "Epoch 27/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.2099 - acc: 0.6125\n",
            "Epoch 28/30\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 1.1847 - acc: 0.6125\n",
            "Epoch 29/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.1586 - acc: 0.6125\n",
            "Epoch 30/30\n",
            "80/80 [==============================] - 7s 85ms/step - loss: 1.1352 - acc: 0.6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh7KFTBXdaj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = np.asarray(x_enc[40:])\n",
        "y_test = np.asarray(y_enc[40:])\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./model.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=32)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVG_eZ8jdbzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "4822c19e-7003-40af-b8f8-69c1e642a38f"
      },
      "source": [
        "\n",
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_preds)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "                             bug       0.00      0.00      0.00         1\n",
            "                 bug|help wanted       0.00      0.00      0.00         2\n",
            "                     enhancement       1.00      0.50      0.67         4\n",
            "         enhancement|help wanted       0.00      0.00      0.00         2\n",
            "enhancement|help wanted|question       0.00      0.00      0.00         1\n",
            "            enhancement|question       0.00      0.00      0.00         3\n",
            "                     help wanted       0.00      0.00      0.00         1\n",
            "             help wanted|invalid       0.00      0.00      0.00         1\n",
            "            help wanted|question       0.00      0.00      0.00         2\n",
            "                         invalid       1.00      0.25      0.40         4\n",
            "                invalid|question       0.00      0.00      0.00         1\n",
            "                        question       0.59      1.00      0.74        29\n",
            "                question|wontfix       0.00      0.00      0.00         1\n",
            "\n",
            "                        accuracy                           0.62        52\n",
            "                       macro avg       0.20      0.13      0.14        52\n",
            "                    weighted avg       0.48      0.62      0.50        52\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNG02At0yGXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pckCKEEe6q4g",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}