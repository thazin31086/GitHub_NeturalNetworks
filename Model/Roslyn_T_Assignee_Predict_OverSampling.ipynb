{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roslyn_T_Assignee_Predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xIbLyam6PAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://medium.com/towards-artificial-intelligence/application-of-synthetic-minority-over-sampling-technique-smote-for-imbalanced-data-sets-509ab55cfdaf\n",
        "#This Code predict Assignee for Roslyn Issues with Title\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from bs4 import BeautifulSoup\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "data = pd.read_csv('IssueDetailsRoslyn_20102019_Single.csv', encoding='latin-1')\n",
        "data = data.reindex(np.random.permutation(data.index))\n",
        "y = list(data['Assignee']) \n",
        "x = list(data['Title']) \n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "\n",
        "categories = list(set(y))\n",
        "\n",
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "\n",
        "test = encode(le,categories)\n",
        "\n",
        "untest = decode(le, test)\n",
        "\n",
        "x_enc = x\n",
        "y_enc = encode(le, y)\n",
        "\n",
        "#80% / 20% train / test split:\n",
        "\n",
        "train_size = int(len(x) * .8)\n",
        "\n",
        "#x_train = np.asarray(x_enc[:train_size])\n",
        "x_train = data['Title'].tolist()\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  x_train = session.run(embed(x_train))\n",
        "#x_train = np.array(x_train[:train_size], dtype=object)[:, np.newaxis]\n",
        "x_train = np.array(x_train[:train_size], dtype=object)\n",
        "y_train = np.asarray(y_enc[:train_size])\n",
        "\n",
        "x_test = np.asarray(x_enc[train_size:])\n",
        "y_test = np.asarray(y_enc[train_size:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSTGywbOSEcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "# X_f and y_f are the Training Set Features and Labels respectively \n",
        "X_res, y_res = ros.fit_resample(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFlOVnLf_klG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93a0384f-eaa9-4924-b231-3a1101d3c015"
      },
      "source": [
        "y_res.shape[1]"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxgn6vzHdReY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkJd2EwW24Rv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82fc6608-8a1f-471d-f650-56caf4cdb853"
      },
      "source": [
        "x_train_SMOTE.shape"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1430, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfe-mPpJdUA0",
        "colab_type": "code",
        "outputId": "ace4905a-29c0-4bc8-96a9-e5381cb1abf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "input_text = Input(shape=(512,))\n",
        "#embedding = Lambda(UniversalEmbedding, output_shape=(512,))(input_text)\n",
        "#Add the dense layer with 256 units and recified learn \n",
        "dense = Dense(256, activation='relu', input_shape=(512,))(input_text)\n",
        "#Add the dense with No of Categories unit and softmax function\n",
        "pred = Dense(y_res.shape[1], activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 46)                11822     \n",
            "=================================================================\n",
            "Total params: 143,150\n",
            "Trainable params: 143,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL5QKGbCdWEs",
        "colab_type": "code",
        "outputId": "4fdbe79d-43c4-4d28-bbeb-078172438f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(X_res, y_res, epochs=100, batch_size=32)\n",
        "    model.save_weights('./model_roslyn_Title_Assignee_Prediction.h5')"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5888/5888 [==============================] - 16s 3ms/step - loss: 2.5353 - acc: 0.5099\n",
            "Epoch 2/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 1.2361 - acc: 0.7040\n",
            "Epoch 3/100\n",
            "5888/5888 [==============================] - 1s 169us/step - loss: 0.9386 - acc: 0.7655\n",
            "Epoch 4/100\n",
            "5888/5888 [==============================] - 1s 169us/step - loss: 0.7723 - acc: 0.8072\n",
            "Epoch 5/100\n",
            "5888/5888 [==============================] - 1s 182us/step - loss: 0.6559 - acc: 0.8346\n",
            "Epoch 6/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.5685 - acc: 0.8567\n",
            "Epoch 7/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.4969 - acc: 0.8758\n",
            "Epoch 8/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.4354 - acc: 0.8939\n",
            "Epoch 9/100\n",
            "5888/5888 [==============================] - 1s 168us/step - loss: 0.3865 - acc: 0.9108\n",
            "Epoch 10/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.3467 - acc: 0.9226\n",
            "Epoch 11/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.3101 - acc: 0.9293\n",
            "Epoch 12/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.2798 - acc: 0.9365\n",
            "Epoch 13/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.2544 - acc: 0.9445\n",
            "Epoch 14/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.2301 - acc: 0.9501\n",
            "Epoch 15/100\n",
            "5888/5888 [==============================] - 1s 187us/step - loss: 0.2082 - acc: 0.9564\n",
            "Epoch 16/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.1913 - acc: 0.9589\n",
            "Epoch 17/100\n",
            "5888/5888 [==============================] - 1s 180us/step - loss: 0.1752 - acc: 0.9647\n",
            "Epoch 18/100\n",
            "5888/5888 [==============================] - 1s 184us/step - loss: 0.1613 - acc: 0.9672\n",
            "Epoch 19/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.1488 - acc: 0.9698\n",
            "Epoch 20/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.1377 - acc: 0.9715\n",
            "Epoch 21/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.1287 - acc: 0.9738\n",
            "Epoch 22/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.1194 - acc: 0.9755\n",
            "Epoch 23/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.1098 - acc: 0.9771\n",
            "Epoch 24/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.1031 - acc: 0.9784\n",
            "Epoch 25/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0982 - acc: 0.9779\n",
            "Epoch 26/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0900 - acc: 0.9820\n",
            "Epoch 27/100\n",
            "5888/5888 [==============================] - 1s 180us/step - loss: 0.0830 - acc: 0.9830\n",
            "Epoch 28/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0785 - acc: 0.9832\n",
            "Epoch 29/100\n",
            "5888/5888 [==============================] - 1s 170us/step - loss: 0.0745 - acc: 0.9854\n",
            "Epoch 30/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.0715 - acc: 0.9859\n",
            "Epoch 31/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0654 - acc: 0.9871\n",
            "Epoch 32/100\n",
            "5888/5888 [==============================] - 1s 171us/step - loss: 0.0633 - acc: 0.9874\n",
            "Epoch 33/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0604 - acc: 0.9874\n",
            "Epoch 34/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0576 - acc: 0.9885\n",
            "Epoch 35/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0543 - acc: 0.9898\n",
            "Epoch 36/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0536 - acc: 0.9881\n",
            "Epoch 37/100\n",
            "5888/5888 [==============================] - 1s 173us/step - loss: 0.0495 - acc: 0.9891\n",
            "Epoch 38/100\n",
            "5888/5888 [==============================] - 1s 170us/step - loss: 0.0479 - acc: 0.9893\n",
            "Epoch 39/100\n",
            "5888/5888 [==============================] - 1s 182us/step - loss: 0.0470 - acc: 0.9886\n",
            "Epoch 40/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.0437 - acc: 0.9908\n",
            "Epoch 41/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0422 - acc: 0.9905\n",
            "Epoch 42/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0393 - acc: 0.9901\n",
            "Epoch 43/100\n",
            "5888/5888 [==============================] - 1s 172us/step - loss: 0.0392 - acc: 0.9912\n",
            "Epoch 44/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0381 - acc: 0.9908\n",
            "Epoch 45/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0363 - acc: 0.9912\n",
            "Epoch 46/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0356 - acc: 0.9913\n",
            "Epoch 47/100\n",
            "5888/5888 [==============================] - 1s 172us/step - loss: 0.0348 - acc: 0.9922\n",
            "Epoch 48/100\n",
            "5888/5888 [==============================] - 1s 182us/step - loss: 0.0337 - acc: 0.9920\n",
            "Epoch 49/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0329 - acc: 0.9922\n",
            "Epoch 50/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0327 - acc: 0.9925\n",
            "Epoch 51/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0314 - acc: 0.9929\n",
            "Epoch 52/100\n",
            "5888/5888 [==============================] - 1s 172us/step - loss: 0.0326 - acc: 0.9907\n",
            "Epoch 53/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0306 - acc: 0.9918\n",
            "Epoch 54/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0297 - acc: 0.9924\n",
            "Epoch 55/100\n",
            "5888/5888 [==============================] - 1s 185us/step - loss: 0.0290 - acc: 0.9927\n",
            "Epoch 56/100\n",
            "5888/5888 [==============================] - 1s 185us/step - loss: 0.0285 - acc: 0.9913\n",
            "Epoch 57/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0280 - acc: 0.9922\n",
            "Epoch 58/100\n",
            "5888/5888 [==============================] - 1s 182us/step - loss: 0.0286 - acc: 0.9925\n",
            "Epoch 59/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0283 - acc: 0.9927\n",
            "Epoch 60/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.0277 - acc: 0.9925\n",
            "Epoch 61/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0285 - acc: 0.9920\n",
            "Epoch 62/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.0261 - acc: 0.9927\n",
            "Epoch 63/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0253 - acc: 0.9929\n",
            "Epoch 64/100\n",
            "5888/5888 [==============================] - 1s 186us/step - loss: 0.0254 - acc: 0.9925\n",
            "Epoch 65/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0248 - acc: 0.9932\n",
            "Epoch 66/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0246 - acc: 0.9929\n",
            "Epoch 67/100\n",
            "5888/5888 [==============================] - 1s 173us/step - loss: 0.0241 - acc: 0.9930\n",
            "Epoch 68/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0264 - acc: 0.9925\n",
            "Epoch 69/100\n",
            "5888/5888 [==============================] - 1s 184us/step - loss: 0.0254 - acc: 0.9930\n",
            "Epoch 70/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0239 - acc: 0.9929\n",
            "Epoch 71/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0239 - acc: 0.9925\n",
            "Epoch 72/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0242 - acc: 0.9922\n",
            "Epoch 73/100\n",
            "5888/5888 [==============================] - 1s 180us/step - loss: 0.0237 - acc: 0.9935\n",
            "Epoch 74/100\n",
            "5888/5888 [==============================] - 1s 184us/step - loss: 0.0223 - acc: 0.9934\n",
            "Epoch 75/100\n",
            "5888/5888 [==============================] - 1s 183us/step - loss: 0.0226 - acc: 0.9930\n",
            "Epoch 76/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0244 - acc: 0.9924\n",
            "Epoch 77/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0247 - acc: 0.9917\n",
            "Epoch 78/100\n",
            "5888/5888 [==============================] - 1s 166us/step - loss: 0.0239 - acc: 0.9924\n",
            "Epoch 79/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0266 - acc: 0.9918\n",
            "Epoch 80/100\n",
            "5888/5888 [==============================] - 1s 174us/step - loss: 0.0252 - acc: 0.9927\n",
            "Epoch 81/100\n",
            "5888/5888 [==============================] - 1s 172us/step - loss: 0.0211 - acc: 0.9935\n",
            "Epoch 82/100\n",
            "5888/5888 [==============================] - 1s 182us/step - loss: 0.0230 - acc: 0.9925\n",
            "Epoch 83/100\n",
            "5888/5888 [==============================] - 1s 173us/step - loss: 0.0216 - acc: 0.9939\n",
            "Epoch 84/100\n",
            "5888/5888 [==============================] - 1s 185us/step - loss: 0.0221 - acc: 0.9935\n",
            "Epoch 85/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0216 - acc: 0.9935\n",
            "Epoch 86/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0214 - acc: 0.9932\n",
            "Epoch 87/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0229 - acc: 0.9925\n",
            "Epoch 88/100\n",
            "5888/5888 [==============================] - 1s 175us/step - loss: 0.0214 - acc: 0.9934\n",
            "Epoch 89/100\n",
            "5888/5888 [==============================] - 1s 177us/step - loss: 0.0212 - acc: 0.9925\n",
            "Epoch 90/100\n",
            "5888/5888 [==============================] - 1s 171us/step - loss: 0.0221 - acc: 0.9937\n",
            "Epoch 91/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0222 - acc: 0.9935\n",
            "Epoch 92/100\n",
            "5888/5888 [==============================] - 1s 181us/step - loss: 0.0228 - acc: 0.9927\n",
            "Epoch 93/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0224 - acc: 0.9934\n",
            "Epoch 94/100\n",
            "5888/5888 [==============================] - 1s 187us/step - loss: 0.0237 - acc: 0.9929\n",
            "Epoch 95/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0218 - acc: 0.9930\n",
            "Epoch 96/100\n",
            "5888/5888 [==============================] - 1s 179us/step - loss: 0.0208 - acc: 0.9937\n",
            "Epoch 97/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0218 - acc: 0.9932\n",
            "Epoch 98/100\n",
            "5888/5888 [==============================] - 1s 176us/step - loss: 0.0219 - acc: 0.9935\n",
            "Epoch 99/100\n",
            "5888/5888 [==============================] - 1s 178us/step - loss: 0.0206 - acc: 0.9939\n",
            "Epoch 100/100\n",
            "5888/5888 [==============================] - 1s 180us/step - loss: 0.0204 - acc: 0.9935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_-8FvC67jIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa2efb0a-dcea-4f74-c29c-bdacdb6780a5"
      },
      "source": [
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  x_test = session.run(embed(x_test))"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh7KFTBXdaj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./model_roslyn_Title_Assignee_Prediction.h5')  \n",
        "    predicts = model.predict(x_train, batch_size=32)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY2Wve_zIMce",
        "colab_type": "code",
        "outputId": "778b864d-5dd9-45b2-dcf5-81c299b77e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_test = np.asarray(y_enc[:train_size])\n",
        "\n",
        "\n",
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "metrics.confusion_matrix(y_test, y_preds)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))\n"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "            333fred       1.00      1.00      1.00        15\n",
            "            AArnott       1.00      1.00      1.00         1\n",
            "    AdamSpeight2008       1.00      1.00      1.00         1\n",
            "          AlekseyTs       1.00      1.00      1.00        10\n",
            "           AmadeusW       1.00      1.00      1.00         2\n",
            "         BillWagner       1.00      1.00      1.00         1\n",
            "            Cosifne       1.00      1.00      1.00         1\n",
            "     CyrusNajmabadi       1.00      1.00      1.00         5\n",
            "          JoeRobich       1.00      0.95      0.97        20\n",
            "        RikkiGibson       1.00      0.97      0.98        30\n",
            "              TIHan       0.00      0.00      0.00         0\n",
            "              abock       0.00      0.00      0.00         1\n",
            "             agocke       0.00      0.00      0.00        19\n",
            "        allisonchou       0.00      0.00      0.00         8\n",
            "               alrz       0.00      0.00      0.00         1\n",
            "            canton7       0.00      0.00      0.00         1\n",
            "           castholm       0.00      0.00      0.00         1\n",
            "             chborl       0.00      0.00      0.00         2\n",
            "           chsienki       0.00      0.00      0.00         3\n",
            "              cston       0.00      0.00      0.00         8\n",
            "            davkean       0.00      0.00      0.00         0\n",
            "           dibarbet       0.00      0.00      0.00        17\n",
            "         dotnet-bot       0.00      0.00      0.00       128\n",
            "dotnet-maestro[bot]       0.00      0.00      0.00         2\n",
            "         drewnoakes       0.00      0.00      0.00         1\n",
            "             gafter       0.00      0.00      0.00        91\n",
            "              genlu       0.00      0.00      0.00        15\n",
            "        heejaechang       0.00      0.00      0.00         0\n",
            "         huoyaoyuan       0.00      0.00      0.00         1\n",
            "          ivanbasov       0.00      0.00      0.00        27\n",
            "           jaredpar       0.00      0.00      0.00        23\n",
            "    jasonmalinowski       0.00      0.00      0.00        24\n",
            "              jcouv       0.00      0.00      0.00        47\n",
            "         jinujoseph       0.00      0.00      0.00        20\n",
            "            jmarolf       0.00      0.00      0.00         1\n",
            "               jnm2       0.00      0.00      0.00         2\n",
            "       kendrahavens       0.00      0.00      0.00         1\n",
            "           mavasani       0.00      0.00      0.00        43\n",
            "          nnpcYvIVl       0.00      0.00      0.00         8\n",
            "             olegtk       0.00      0.00      0.00         1\n",
            "           petrroll       0.00      0.00      0.00        10\n",
            "       reaction1989       0.00      0.00      0.00         1\n",
            "           ryzngard       0.00      0.00      0.00        23\n",
            "           sharwell       0.00      0.00      0.00        76\n",
            "        stephentoub       0.00      0.00      0.00         2\n",
            "              svick       0.00      0.00      0.00         0\n",
            "               tmat       0.00      0.00      0.00        16\n",
            "          tmeschter       0.00      0.00      0.00         1\n",
            "          tuespetre       0.00      0.00      0.00         1\n",
            "    vatsalyaagrawal       0.00      0.00      0.00         3\n",
            "\n",
            "           accuracy                           0.12       715\n",
            "          macro avg       0.20      0.20      0.20       715\n",
            "       weighted avg       0.12      0.12      0.12       715\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNG02At0yGXV",
        "colab_type": "code",
        "outputId": "0cc87816-5f06-4e19-fe3a-cbaba1e955a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "#statistics\n",
        "data['word_count'] = data['Description'].apply(lambda x: len(str(x).split()))\n",
        "desc_lengths = list(data['word_count'])\n",
        "print(\"Number of descriptions:\",len(desc_lengths),\n",
        "      \"\\nAverage word count\", np.average(desc_lengths),\n",
        "      \"\\nMinimum word count\", min(desc_lengths),\n",
        "      \"\\nMaximum word count\", max(desc_lengths))\n",
        "\n",
        "#Model Graph\n",
        "plot_model(model, to_file='model_roslyn_Title_Assignee_Prediction_plot.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
        "\n",
        "#SVG Diagram\n",
        "#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
        "\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of descriptions: 895 \n",
            "Average word count 90.37430167597765 \n",
            "Minimum word count 1 \n",
            "Maximum word count 1220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-12f28154a795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pckCKEEe6q4g",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}